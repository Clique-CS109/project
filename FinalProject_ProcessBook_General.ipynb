{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Book Recommendation with Machine Learning\n",
    "<img src = \"https://img.grouponcdn.com/seocms/ajPaKzNP9U8cyrZ5vyexnD/10-Handwritten-Book-Recommendations-from-Unabridged-Bookstore_600c390-600x390.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Overview\n",
    "Online book store in Korea is as prosperous as in any other countries in the world. It has about 36% of entire book market share in Korea, and this number is consitently growing every year. *YES24* is the leading online book store in Korea, occupying about 44% of online book market. However, *YES24*'s book recommender system is not so good that it often recommends totally irrelavant books, or even a goods that is not a book. *YES24* recently opened a competition where data scientists suggest a solution for accurate book recommender, releasing the purchase history of 19,000 users within 2014. This motivated us to build a book recommeder algorithm, using the technique we've learned throughout the semester in CS109. <br><br>\n",
    "We've tried three different algorithms: one is the simplest algorithm that *YES24* supposedly uses on their current website, and the others are based on k-nearest neighbor (kNN) with user similarity and book similarity. As a result, we found that kNN with user similarity has the best recommendation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data\n",
    "The data given by *YES24* contains the information of 511,742 transactions of about 19,000 users' purchase history, involving about 19,000 books, in the following fields:\n",
    "\n",
    "- Customer ID: unique, encrypted customer identification `ID`\n",
    "- Transaction Date `Date`\n",
    "- Book Title `Title`\n",
    "- Type of transaction: takes either ordered, cancelled, or refunded `Class`\n",
    "- Book Category: Foreign literature, Korean literature, Religion, Self-Development, or Humanities `Category`\n",
    "- Author: `Author`\n",
    "- ISBN code of book. '-' or 'nan' if not available `ISBN`\n",
    "- Publisher `Publisher`\n",
    "- Published date `Pub_Date`\n",
    "- Transaction Time `Order_Time`\n",
    "- Number of books in the transaction: Positive integer if purchased, and negative if refunded or cancelled. `Count`\n",
    "- Whether or not a book has been in cart: 1 if so, 0 if not `Cart`\n",
    "- Date when a book was added to cart `Cart_Date`\n",
    "- Device used to make a transaction `Device`\n",
    "- Address: `Address1` and more detailed address in `Address2`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning\n",
    "\n",
    "A first and the important step is cleaning the given raw data. In our case, we have `cancel` and `return` transactions along with `purchase` ones. However, `cancel` and `return` transactions should not be considered since the recommendation of books heavily rely on what the customer purchased before. Moreover, when we remove the `cancel` and `return` transactions, corresponding `purchase` transactions should be removed as well. \n",
    "\n",
    "As a result, we can see that originally, we had \n",
    "\n",
    "| Original Set               | Pruchase         |  Cancel        |  Return            |  \n",
    "| :--------------------: |:-------------------:| :-------------------:| :-------------------:| \n",
    "| No. of Transactions   | 511742 | 19264 | 3877|\n",
    "\n",
    "and once we remove all the `cancel` and `remove` transactions along with corresponding `purchase` transactions, we end up having\n",
    "\n",
    "| Original Set               | Pruchase         |  Cancel        |  Return            |  \n",
    "| :--------------------: |:-------------------:| :-------------------:| :-------------------:| \n",
    "| No. of Transactions   | 488874 | 55 | 218|\n",
    "\n",
    "Please note that the numbers indicate `(No of purchases) (No of cancels) (No of returns)`. As can be observed, we still have some `cancel` and `return` transactions. This might be due to a wrong training-test split by the provider - *YES24*. The 273 transactions of cancel and return do not have corresponding purchase transactions in the given data. We'll drop remaining 273 transactions as well, and only consider 488,874 transactions. For the purpose of this project, we only take into account following 5 large categories: \n",
    "\n",
    "- `Korean Literature`\n",
    "- `Humanities`\n",
    "- `Self Development`\n",
    "- `Religion`\n",
    "- `International Literature`.\n",
    "\n",
    "Once we do all the data cleaning works, we can now move on to the training-validate-test split process. As we have done in the homework. What we do here is we consider customers with more than (or equal to) $N$ purchases. For those who have made more than $N$ purchases, we choose randomly $M$ transactions and put them to validate set, and randomly select another $L$ transactions (exclusively) to put them into test set. $N$, $M$, and $L$ differ from category to category. Those numbers are determined heuristically. More detailed explanation along with executable code can be found in the ipython notebook of [`Data_Exploration.ipynb`](https://github.com/Clique-CS109/project/blob/master/Data_Exploration.ipynb). The resulted number of transactions in the training, validate, and test sets are shown in below.\n",
    "\n",
    "\n",
    "\n",
    "| Category               | Trainin Set         |  Validate Set        |  Test Set            |  \n",
    "| :--------------------: |:-------------------:| :-------------------:| :-------------------:| \n",
    "| Foreign Literature     | 28,851 | 3,420 | 2,280 |\n",
    "| Korean Literature      |21,726 | 1,818 | 1,212|\n",
    "| Religion               |10,394 | 1,268 | 951 |\n",
    "| Self-Development       | 15,808 | 1,592 | 1,194|\n",
    "| Humanities             |15,053 |1,488 | 1,116 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Writing Book Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0 Evaluation of Algorithms\n",
    "Each algorithm, the recommendation accuracy $\\Lambda$ is evaluated, which is defined as:\n",
    "$$\\Lambda = \\frac{1}{N} \\sum^N_{u=1} \\frac{|Y_u \\cap P_u|}{|Y_u|}$$\n",
    "where $Y_u$ is the set of books that a user $u$ in the test set purchased, and $P_u$ is the set of books recommended to the user $u$, and $N$ is the total number of users in the test set.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Baseline Algorithm\n",
    "\n",
    "We first start from the simplest algorithm. For each customer in training set, we correct all the previous transactions. This will give us the set of purchased books per customer. Then we look for all the customers who bought books in this set. This now becomes the set of customers (set of close customers). Last we obtain the list of books bought by each customer in this set. We can compute the histogram from the list. We sort the list with respect to the probability of books and recomend to the customer. The executable code can be found in the ipython notebook of [`Base_Model.ipynb`](https://github.com/Clique-CS109/project/blob/master/Base_Model.ipynb).\n",
    "\n",
    "The recommendation accuracy for each category is shown below:\n",
    "\n",
    "| Category               | Accuracy            |  \n",
    "| :--------------------: |:-------------------:| \n",
    "| Foreign Literature     | 7.5%                | \n",
    "| Korean Literature    | 5.6%                | \n",
    "| Religion               | 1.9%                | \n",
    "| Self-Development       | 6.3%                |\n",
    "| Humanities             | 4.7%                |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 kNN using book similarity\n",
    "\n",
    "Then we wrote a kNN algorithm using the similarity between books as a distance metric. In this algorithm, for a given user, the books with the largest similarities with the books that the user has purchased are selected for recommendation. The weight for each of title, author, and publisher similarities is determined through the optimization of recommendation accuracy in validation set. The detailed description and working code may be found in the ipython notebook, [`BookSim.ipynb`](https://github.com/Clique-CS109/project/blob/master/BookSim.ipynb).\n",
    "\n",
    "The recommendation accuracy for each category is shown below:\n",
    "\n",
    "| Category               | Accuracy            |  \n",
    "| :--------------------: |:-------------------:| \n",
    "| Foreign Literature     | 4.2%                | \n",
    "| Korean Literature    | 2.6%                | \n",
    "| Religion               | 4.0%                | \n",
    "| Self-Development       | 2.4%                |\n",
    "| Humanities             | 2.9%                |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 kNN using user similarity\n",
    "\n",
    "We moved on to the third algorithm based on kNN method which deals with similarity between users. Here we deal with three different methds as follows. Detailed description and actual codes can be found in [`userkNN.ipynb`](https://github.com/Clique-CS109/project/blob/master/userkNN.ipynb).\n",
    "\n",
    "#### 4.3.1. Based only on the popularity of books\n",
    "This is to use only the popularity of each book. The recommendation accuracy of this method is as follows.\n",
    "\n",
    "| Category               | Accuracy            |  \n",
    "| :--------------------: |:-------------------:| \n",
    "| Foreign Literature     | 4.2%                | \n",
    "| Korean Literature    | 3.5%                | \n",
    "| Religion               | 0.2%                | \n",
    "| Self-Development       | 5.7%                |\n",
    "| Humanities             | 3.4%                |\n",
    "\n",
    "\n",
    "#### 4.3.2. Based on kNN method (called kNN-only or user kNN)\n",
    "We used kNN method for similarity between users. This is similar to 4.1 above, but we carefully determined how to calculate the score of each book. Also for choosing $k$ we did grid-search on the validation data. The optimak $k$ and the recommendation accuracy is as follows.\n",
    "\n",
    "| Category              | $k$      |  Accuracy            |  \n",
    "| :--------------------:|:--------:|:-------------------:| \n",
    "| Foreign Literature    |  125     | 13.9%                | \n",
    "| Korean Literature     |  342     | 11.9%                | \n",
    "| Religion              |  270     | 5.5%                | \n",
    "| Self-Development      |  169     | 7.7%                |\n",
    "| Humanities            |  372     | 6.3%                |\n",
    "\n",
    "\n",
    "#### 4.3.3. Based on kNN method (called weighted kNN)\n",
    "Then we mixed two aforementioned methods. We chose scores of books as a weighted sum of the first two, where the weight $\\alpha$ and $k$ for kNN were chosen by grid-search on the validation data. The optimal ($k$, $\\alpha$) recommendation accuracy is as follows.\n",
    "\n",
    "\n",
    "| Category              | $(k, \\alpha)$      |  Accuracy            |  \n",
    "| :--------------------:|:--------:|:-------------------:| \n",
    "| Foreign Literature    |  (125,0.37)     | 13.5%                | \n",
    "| Korean Literature     |  (326, 0.045)     | 11.6%                | \n",
    "| Religion              |  (53,0.16)     | 5.2%                | \n",
    "| Self-Development      |  (54,0.059)     | 6.0%                |\n",
    "| Humanities            |  (107, 0.039)     | 5.8%                |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Results\n",
    "\n",
    "Here is the summary of our result. Baseline, Book kNN, Popularity, User kNN, Weighted User kNN on the graph, respectively, indicates the method of 4.1, 4.2, 4.3.1, 4.3.2, 4.3.3, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src = \"http://clique-cs109.github.io/img/graph.png\" style=\"width: 600px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We see that the \"user kNN\" method gives the best result among the five. Also, if we compare the baseline method which is supposedly used currently by *YES24* with the user kNN method, we can see the improvement of recommendation accuracy by 1.4~6.4%p. If we look at the ratio of the recommendation accuracy of these two, we see that user kNN method would give correct answers 22~189% more than the baseline method. It is a huge improvement - we expect it would contribute to raise profit of the online bookstore effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
